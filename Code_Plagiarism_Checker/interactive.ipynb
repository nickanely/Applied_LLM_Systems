{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T09:26:41.586323Z",
     "start_time": "2025-11-29T09:26:41.580580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import tree_sitter_python as tspython\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from tree_sitter import Language, Parser"
   ],
   "id": "cc9e9c6f38ee6375",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "I set up a Python-based plagiarism detection pipeline that combines embedding-based search, BM25 retrieval, and LLM analysis. I did the following:\n",
    "\n",
    "- Configured API keys and environment, initialized OpenAI client, Tree-sitter parser, and tokenizer.\n",
    "- Created directories for indexes and data storage.\n",
    "- Implemented helpers for batch embedding generation and code tokenization.\n",
    "- Built retrieval functions:\n",
    "  - Dense retrieval using FAISS embeddings.\n",
    "  - Sparse retrieval using BM25.\n",
    "  - Hybrid retrieval combining dense + BM25 with Reciprocal Rank Fusion (RRF).\n",
    "- Integrated LLM-based plagiarism checking:\n",
    "  - Generated a prompt with query and reference code.\n",
    "  - Parsed LLM JSON responses for plagiarism verdict, confidence, and explanations.\n",
    "- Created four callable detection functions:\n",
    "  1. Pure embedding similarity check.\n",
    "  2. Direct LLM analysis.\n",
    "  3. Standard RAG (dense retrieval + LLM).\n",
    "  4. Hybrid RAG (dense + sparse retrieval + LLM).\n",
    "- Tested the full pipeline on a sample function, returning structured detection results including confidence, matched references, and retrieved top functions.\n",
    "\n",
    "\n",
    "\n",
    "# NOTE: I have not used structured output deliberately. While it is good practice to use them, in my scenario It was not working well, gave me overhead and some complications - thus I removed them\n"
   ],
   "id": "39fe3268757e9d25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T09:26:41.902878Z",
     "start_time": "2025-11-29T09:26:41.601574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# I have stored my keys in run configuration\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"API key missing. Fix your setup.\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "PY_LANGUAGE = Language(tspython.language())\n",
    "parser = Parser(PY_LANGUAGE)\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "INDEX_DIR = Path(\"indexes\")\n",
    "INDEX_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "EMBEDDING_MODEL = \"text-embedding-3-large\"\n",
    "LLM_MODEL = \"gpt-5-nano\"\n",
    "BATCH_SIZE = 128"
   ],
   "id": "c6f5b65fee82eb44",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-29T09:26:41.914118Z",
     "start_time": "2025-11-29T09:26:41.911095Z"
    }
   },
   "source": [
    "\n",
    "def load_indexes():\n",
    "    \"\"\"Load pre-built indexes and corpus\"\"\"\n",
    "    dense_index = faiss.read_index(str(INDEX_DIR / \"dense.faiss\"))\n",
    "\n",
    "    with open(INDEX_DIR / \"bm25.pkl\", 'rb') as f:\n",
    "        sparse_index = pickle.load(f)\n",
    "\n",
    "    corpus = pd.read_csv(DATA_DIR / \"reference_corpus.csv\")\n",
    "\n",
    "    return dense_index, sparse_index, corpus"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Helpers",
   "id": "30a88bcbd37e8e99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T09:26:41.925732Z",
     "start_time": "2025-11-29T09:26:41.921943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def embed_batch(texts, batch_size=BATCH_SIZE):\n",
    "    \"\"\"Generate embeddings in batches using OpenAI API\"\"\"\n",
    "    all_embeds = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        resp = client.embeddings.create(model=EMBEDDING_MODEL, input=batch)\n",
    "        all_embeds.extend([d.embedding for d in resp.data])\n",
    "    return np.array(all_embeds, dtype=np.float32)\n",
    "\n",
    "def tokenize_code(code):\n",
    "    \"\"\"Tokenize code for BM25 (alphanumeric + symbols)\"\"\"\n",
    "    return re.findall(r'[A-Za-z0-9_]+|[^A-Za-z0-9_\\s]', code)"
   ],
   "id": "13997edb29fae7ef",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Retrievers",
   "id": "5035154b649a358a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T09:26:41.941960Z",
     "start_time": "2025-11-29T09:26:41.934257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def dense_retrieve(query_code, dense_index, corpus, top_k=10):\n",
    "    \"\"\"Retrieve using dense embeddings only\"\"\"\n",
    "    query_emb = embed_batch([query_code])[0].reshape(1, -1)\n",
    "    faiss.normalize_L2(query_emb)\n",
    "\n",
    "    scores, indices = dense_index.search(query_emb, top_k)\n",
    "\n",
    "    results = corpus.iloc[indices[0]].copy()\n",
    "    results['similarity'] = scores[0]\n",
    "    return results.reset_index(drop=True)\n",
    "\n",
    "def sparse_retrieve(query_code, sparse_index, corpus, top_k=10):\n",
    "    \"\"\"Retrieve using BM25 only\"\"\"\n",
    "    query_tokens = tokenize_code(query_code)\n",
    "    scores = sparse_index.get_scores(query_tokens)\n",
    "    top_indices = np.argsort(scores)[::-1][:top_k]\n",
    "\n",
    "    results = corpus.iloc[top_indices].copy()\n",
    "    results['bm25_score'] = scores[top_indices]\n",
    "    return results.reset_index(drop=True)\n",
    "\n",
    "def hybrid_retrieve(query_code, dense_index, sparse_index, corpus, top_k=10, rrf_k=60):\n",
    "    \"\"\"Retrieve using hybrid fusion (RRF)\"\"\"\n",
    "    # Dense retrieval\n",
    "    dense_results = dense_retrieve(query_code, dense_index, corpus, top_k * 2)\n",
    "    dense_ranks = {row['id']: i for i, (_, row) in enumerate(dense_results.iterrows())}\n",
    "\n",
    "    # Sparse retrieval\n",
    "    sparse_results = sparse_retrieve(query_code, sparse_index, corpus, top_k * 2)\n",
    "    sparse_ranks = {row['id']: i for i, (_, row) in enumerate(sparse_results.iterrows())}\n",
    "\n",
    "    # RRF fusion\n",
    "    all_ids = set(dense_ranks.keys()) | set(sparse_ranks.keys())\n",
    "    fused_scores = {}\n",
    "\n",
    "    for doc_id in all_ids:\n",
    "        score = 0\n",
    "        if doc_id in dense_ranks:\n",
    "            score += 1 / (rrf_k + dense_ranks[doc_id])\n",
    "        if doc_id in sparse_ranks:\n",
    "            score += 1 / (rrf_k + sparse_ranks[doc_id])\n",
    "        fused_scores[doc_id] = score\n",
    "\n",
    "    # Sort and select top-k\n",
    "    top_ids = sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    results = corpus[corpus['id'].isin([doc_id for doc_id, _ in top_ids])].copy()\n",
    "    results['fused_score'] = results['id'].map(dict(top_ids))\n",
    "    results = results.sort_values('fused_score', ascending=False)\n",
    "\n",
    "    return results.reset_index(drop=True)"
   ],
   "id": "a91a82bb1ae63091",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ask LLM",
   "id": "cbc60f271404c6eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T09:26:41.954816Z",
     "start_time": "2025-11-29T09:26:41.950056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def ask_llm_plagiarism(query_code, context_codes):\n",
    "    \"\"\"Ask LLM to determine plagiarism given context\"\"\"\n",
    "    context_str = \"\\n\\n---\\n\\n\".join([\n",
    "        f\"REFERENCE {i+1}:\\n```python\\n{code}\\n```\"\n",
    "        for i, code in enumerate(context_codes)\n",
    "    ])\n",
    "\n",
    "    prompt = f\"\"\"You are a code plagiarism detector. Analyze if the QUERY code is plagiarized from any REFERENCE code.\n",
    "\n",
    "QUERY CODE:\n",
    "```python\n",
    "{query_code}\n",
    "```\n",
    "\n",
    "REFERENCE CODES:\n",
    "{context_str}\n",
    "\n",
    "Determine:\n",
    "1. Is the query plagiarized? (YES/NO)\n",
    "2. If yes, which reference(s)?\n",
    "3. Plagiarism confidence (0.0-1.0)\n",
    "4. Brief explanation\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"is_plagiarized\": true/false,\n",
    "  \"confidence\": 0.0-1.0,\n",
    "  \"matched_references\": [1, 2, ...],\n",
    "  \"explanation\": \"brief reason\"\n",
    "}}\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=LLM_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].message.content.strip()\n",
    "    result = result.replace('```json', '').replace('```', '').strip()\n",
    "\n",
    "    try:\n",
    "        return json.loads(result)\n",
    "    except:\n",
    "        return {\"is_plagiarized\": False, \"confidence\": 0.0, \"matched_references\": [], \"explanation\": \"Parse error\"}\n"
   ],
   "id": "fa9c699b7c374b73",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4 Callable Functions - Detections",
   "id": "bb76b8b848fcec3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T09:26:41.967614Z",
     "start_time": "2025-11-29T09:26:41.961843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def detect_embedding(query_code, threshold=0.8):\n",
    "    \"\"\"System 1: Pure embedding search with threshold\"\"\"\n",
    "    dense_index, _, corpus = load_indexes()\n",
    "\n",
    "    results = dense_retrieve(query_code, dense_index, corpus, top_k=5)\n",
    "\n",
    "    # Check if any result exceeds threshold\n",
    "    is_plagiarized = (results['similarity'].max() >= threshold)\n",
    "\n",
    "    return {\n",
    "        \"method\": \"embedding\",\n",
    "        \"is_plagiarized\": bool(is_plagiarized),\n",
    "        \"max_similarity\": float(results['similarity'].max()),\n",
    "        \"threshold\": threshold,\n",
    "        \"top_matches\": results[['function_name', 'similarity', 'file_path']].to_dict('records')\n",
    "    }\n",
    "\n",
    "def detect_llm(query_code, max_context_functions=5000):\n",
    "    \"\"\"System 2: Direct LLM analysis with full corpus context\n",
    "    !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    NOTE!!!! May be limited due to model context limitations.\n",
    "    During testing, I couldn't pass whole corpus\n",
    "    !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    \"\"\"\n",
    "    _, _, corpus = load_indexes()\n",
    "\n",
    "    # Sample corpus (or use full if small enough)\n",
    "    context_sample = corpus.sample(n=min(max_context_functions, len(corpus)))\n",
    "    context_codes = context_sample['code'].tolist()\n",
    "\n",
    "    llm_result = ask_llm_plagiarism(query_code, context_codes)\n",
    "\n",
    "    return {\n",
    "        \"method\": \"direct_llm\",\n",
    "        \"is_plagiarized\": llm_result[\"is_plagiarized\"],\n",
    "        \"confidence\": llm_result[\"confidence\"],\n",
    "        \"explanation\": llm_result[\"explanation\"],\n",
    "        \"context_size\": len(context_codes)\n",
    "    }\n",
    "\n",
    "def detect_rag(query_code, top_k=5):\n",
    "    \"\"\"System 3: Standard RAG (dense retrieval + LLM)\"\"\"\n",
    "    dense_index, _, corpus = load_indexes()\n",
    "\n",
    "    # Retrieve relevant context\n",
    "    results = dense_retrieve(query_code, dense_index, corpus, top_k=top_k)\n",
    "    context_codes = results['code'].tolist()\n",
    "\n",
    "    # LLM analysis\n",
    "    llm_result = ask_llm_plagiarism(query_code, context_codes)\n",
    "\n",
    "    return {\n",
    "        \"method\": \"rag\",\n",
    "        \"is_plagiarized\": llm_result[\"is_plagiarized\"],\n",
    "        \"confidence\": llm_result[\"confidence\"],\n",
    "        \"explanation\": llm_result[\"explanation\"],\n",
    "        \"retrieved_functions\": results[['function_name', 'similarity']].to_dict('records')\n",
    "    }\n",
    "\n",
    "def detect_hybrid_rag(query_code, top_k=5):\n",
    "    \"\"\"System 4: Hybrid RAG (dense + BM25 + LLM)\"\"\"\n",
    "    dense_index, sparse_index, corpus = load_indexes()\n",
    "\n",
    "    # Hybrid retrieval\n",
    "    results = hybrid_retrieve(query_code, dense_index, sparse_index, corpus, top_k=top_k)\n",
    "    context_codes = results['code'].tolist()\n",
    "\n",
    "    # LLM analysis\n",
    "    llm_result = ask_llm_plagiarism(query_code, context_codes)\n",
    "\n",
    "    return {\n",
    "        \"method\": \"hybrid_rag\",\n",
    "        \"is_plagiarized\": llm_result[\"is_plagiarized\"],\n",
    "        \"confidence\": llm_result[\"confidence\"],\n",
    "        \"explanation\": llm_result[\"explanation\"],\n",
    "        \"retrieved_functions\": results[['function_name', 'fused_score']].to_dict('records')\n",
    "    }\n"
   ],
   "id": "76a0fd3fa5ab4195",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T09:27:09.532379Z",
     "start_time": "2025-11-29T09:26:41.977530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Step 2: Test detection\n",
    "test_code = \"\"\"\n",
    "def vector_components(size: float, direction: float, in_radians: bool = False) -> list[float]:\\n    if in_radians: \\n        return [size * cos(direction), size * sin(direction)]\\n    return [size * cos(radians(direction)), size * sin(radians(direction))]\",\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(detect_embedding(test_code))\n",
    "print(detect_llm(test_code, 40))\n",
    "print(detect_rag(test_code))\n",
    "print(detect_hybrid_rag(test_code))"
   ],
   "id": "1601fee8b64e0eb1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'embedding', 'is_plagiarized': False, 'max_similarity': 0.40369856357574463, 'threshold': 0.8, 'top_matches': [{'function_name': 'polar_force', 'similarity': 0.40369856357574463, 'file_path': 'data\\\\repos\\\\Python\\\\physics\\\\in_static_equilibrium.py'}, {'function_name': 'create_canvas', 'similarity': 0.387052446603775, 'file_path': 'data\\\\repos\\\\Python\\\\cellular_automata\\\\game_of_life.py'}, {'function_name': 'random_vector', 'similarity': 0.3262872099876404, 'file_path': 'data\\\\repos\\\\Python\\\\linear_algebra\\\\src\\\\lib.py'}, {'function_name': 'component', 'similarity': 0.3261396884918213, 'file_path': 'data\\\\repos\\\\Python\\\\linear_algebra\\\\src\\\\lib.py'}, {'function_name': 'projection', 'similarity': 0.32332220673561096, 'file_path': 'data\\\\repos\\\\Python\\\\linear_algebra\\\\src\\\\transformations_2d.py'}]}\n",
      "{'method': 'direct_llm', 'is_plagiarized': False, 'confidence': 0.15, 'explanation': 'The QUERY code defines a small helper to compute the x,y components of a vector given magnitude and direction, optionally converting from degrees to radians. None of the provided REFERENCE codes contain an equivalent function or the exact same logic/structure (or near-identical formatting) for vector components or trig-based component extraction. The references cover unrelated algorithms (sorting, mergesort, graph traversals, weather fetch, etc.). Therefore, no clear plagiarism is detected from the given references.', 'context_size': 40}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'rag', 'is_plagiarized': True, 'confidence': 0.9, 'explanation': 'The function performs polar-to-Cartesian conversion (component extraction from size/magnitude and direction/angle) with an option to treat the angle as radians or convert from degrees. This exact approach and conditional structure strongly mirror REFERENCE 1 (polar_force with radian_mode), differing mainly in parameter names (size vs magnitude, direction vs angle, in_radians vs radian_mode). This indicates high similarity and likely plagiarism.', 'retrieved_functions': [{'function_name': 'polar_force', 'similarity': 0.4037018418312073}, {'function_name': 'create_canvas', 'similarity': 0.3871239423751831}, {'function_name': 'random_vector', 'similarity': 0.32625970244407654}, {'function_name': 'component', 'similarity': 0.32609403133392334}, {'function_name': 'projection', 'similarity': 0.32339274883270264}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding: 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'hybrid_rag', 'is_plagiarized': True, 'confidence': 0.85, 'explanation': 'The function vector_components performs polar-to-Cartesian conversion with two branches (angles in radians vs degrees) using [size * cos(angle), size * sin(angle)]. This mirrors REFERENCE 1 (polar_force) almost identically, including the same logic and structure (radian_mode handling and the non-radian path using radians(angle)). The only notable differences are parameter names; this strongly suggests copying from REFERENCE 1.', 'retrieved_functions': [{'function_name': 'polar_force', 'fused_score': 0.03333333333333333}, {'function_name': 'minCost', 'fused_score': 0.01639344262295082}, {'function_name': 'create_canvas', 'fused_score': 0.01639344262295082}, {'function_name': 'exits_word', 'fused_score': 0.016129032258064516}, {'function_name': 'random_vector', 'fused_score': 0.016129032258064516}]}\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T09:27:09.563520Z",
     "start_time": "2025-11-29T09:27:09.561164Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "52aa40676242e79a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
